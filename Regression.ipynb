{"cells":[{"cell_type":"markdown","metadata":{"id":"ok1V8zOJSGxI"},"source":["# Homework 1: COVID-19 Cases Prediction (Regression)"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19971,"status":"ok","timestamp":1709216805822,"user":{"displayName":"葉佐晨","userId":"06695019314315633787"},"user_tz":-480},"id":"ZJL8FUdKPk_q","outputId":"5bc42971-1fed-47d6-9c9b-df5eb236dc03"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","[Errno 2] No such file or directory: '/MyDrive/Colab Notebooks/Machine Learning 2023 Spring'\n","/content\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":488,"status":"ok","timestamp":1709217222972,"user":{"displayName":"葉佐晨","userId":"06695019314315633787"},"user_tz":-480},"id":"f8POyBkWQA2P","outputId":"a3ff4e89-00b2-449e-9ac6-07c3b374cb8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/MyDrive/Colab Notebooks/Machine Learning 2023 Spring'\n","/content/drive/MyDrive/Colab Notebooks/Machine Learning 2023 Spring\n"]}],"source":["%cd \"drive/MyDrive/Colab Notebooks/Machine Learning 2023 Spring\""]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709217376863,"user":{"displayName":"葉佐晨","userId":"06695019314315633787"},"user_tz":-480},"id":"plP8giYpS1hM","outputId":"cd410c6d-0020-4be1-95fc-2bb86b6656f1"},"outputs":[{"data":{"text/plain":["'g:\\\\My Drive\\\\Colab Notebooks\\\\Machine Learning 2023 Spring'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["%pwd"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1709217255624,"user":{"displayName":"葉佐晨","userId":"06695019314315633787"},"user_tz":-480},"id":"zNCMZItbSXhX","outputId":"6814b589-6d88-4c22-fa68-51fad8ad047c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Feb 29 14:34:14 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2781,"status":"ok","timestamp":1709217487138,"user":{"displayName":"葉佐晨","userId":"06695019314315633787"},"user_tz":-480},"id":"FxTxvKa9SdYw","outputId":"9ecdc442-be4b-4cf0-efed-efb2cf6b6bda"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1Xmtq-NZlaWNhjV2FOonpbvBTXIzyXauf\n","To: /content/covid_train.csv\n","100% 2.16M/2.16M [00:00<00:00, 151MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1V-JKYCKyjktlHA9Dh1jQHbvHsewQOtsr\n","To: /content/covid_test.csv\n","100% 638k/638k [00:00<00:00, 128MB/s]\n"]}],"source":["!gdown --fuzzy \"https://drive.google.com/file/d/1Xmtq-NZlaWNhjV2FOonpbvBTXIzyXauf/view?usp=sharing\" --output \"covid_train.csv\"\n","!gdown --fuzzy \"https://drive.google.com/file/d/1V-JKYCKyjktlHA9Dh1jQHbvHsewQOtsr/view?usp=sharing\" --output \"covid_test.csv\""]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1709217720010,"user":{"displayName":"葉佐晨","userId":"06695019314315633787"},"user_tz":-480},"id":"psEPHn8iSYrv"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\zuoch\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n"]}],"source":["# numerical operations\n","import math\n","import numpy as np\n","\n","# reading/writing data\n","import pandas as pd\n","import os\n","import csv\n","\n","# for progress bar\n","from tqdm import tqdm\n","\n","# pytorch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","# for plotting learning curve\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"markdown","metadata":{"id":"jr7SAvEnUSuC"},"source":["## Some Utility Functions"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"wNx387uhUKKl"},"outputs":[],"source":["def same_seed(seed):\n","  \"\"\"Fixes random numer generator see\"\"\"\n","  torch.backends.cudnn.deterministic = True\n","  torch.backends.cudnn.benchmark = False\n","  np.random.seed(seed)\n","  torch.manual_seed(seed)\n","  if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","def train_valid_split(data_set, valid_ratio, seed):\n","  \"\"\"Split provided training data into training set and validation set\"\"\"\n","  valid_set_size = int(valid_ratio*len(data_set))\n","  train_set_size = len(data_set) - valid_set_size\n","  train_set, valid_set = random_split(data_set, [train_set_size, valid_set_size], generator=torch.Generator().manual_seed(seed))\n","  return np.array(train_set), np.array(valid_set)\n","\n","def predict(test_loader, model, device):\n","  model.eval()  # set your model to evaluation mode\n","  preds = []\n","  for x in tqdm(test_loader):\n","    x = x.to(device)\n","    with torch.no_grad():\n","      pred = model(x)\n","      preds.append(pred.detach().cpu())\n","  preds = torch.cat(preds, dim=0).numpy()\n","  return preds"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class COVID90Dataset(Dataset):\n","    \"\"\"\n","    x: Features\n","    y: Targets, if none, do prediction\n","    \"\"\"\n","    def __init__(self, x, y=None):\n","        if y is None:\n","            self.y = y\n","        else:\n","            self.y = torch.FloatTensor(y)\n","        self.x = torch.FloatTensor(x)\n","\n","    def __getitem__(self, idx):\n","        if self.y is None:\n","            return self.x[idx]\n","        else:\n","            return self.x[idx], self.y[idx]\n","        \n","    def __len__(self):\n","        return(len(self.x))"]},{"cell_type":"markdown","metadata":{},"source":["## Neural Network Model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["class My_Model(nn.Module):\n","    def __init__(self, input_dim):\n","        super(My_Model, self).__init__()\n","        # todo: modify model's stucture, be aware of dimensions\n","        self.layers = nn.Sequential(\n","            nn.Linear(input_dim, 16),\n","            nn.ReLU(),\n","            nn.Linear(16, 8),\n","            nn.ReLU(),\n","            nn.Linear(8, 1)\n","        )\n","    \n","    def forward(self, x):\n","        x = self.layers(x)\n","        x = x.squeeze(1)  # (B, 1) -> (B)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Feature Selection"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def select_feat(train_data, valid_data, test_data, select_all=True):\n","    \"\"\"Selects useful features to preform regression\"\"\"\n","    y_train, y_valid = train_data[:, -1], valid_data[:, -1]\n","    raw_x_train, raw_x_valid, raw_x_test = train_data[:, :-1], valid_data[:, :-1], test_data\n","\n","    if select_all:\n","        feat_idx = list(range(raw_x_train.shape[1]))\n","    else:\n","        feat_idx = [0, 1, 2, 3, 4]  # todo: select suitable feature columns\n","    \n","    return raw_x_train[:, feat_idx], raw_x_valid[:, feat_idx], raw_x_test[:, feat_idx], y_train, y_valid"]},{"cell_type":"markdown","metadata":{},"source":["## Training Loop"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def trainer(train_loader, valid_loader, model, config, device):\n","    criterion = nn.MSELoss(reduction=\"mean\")\n","    optimizer = torch.optim.SGD(model.parameters(), lr=config[\"learning_rate\"], momentum=0.9)\n","    writer = SummaryWriter()  # writer to tensorboard\n","\n","    if not os.path.isdir(\"./models\"):\n","        os.mkdir(\"./models\")  # create a directory of saving model\n","\n","    n_epochs, best_loss, step, early_stop_count = config[\"n_epochs\"], math.inf, 0, 0\n","\n","    for epoch in range(n_epochs):\n","        model.train()  # set model to train mode\n","        loss_record = []\n","        train_pbar = tqdm(train_loader, position=0, leave=True)  # visualize training progress\n","\n","        for x, y in train_pbar:\n","            optimizer.zero_grad()  # set gradient to zero\n","            x, y = x.to(device), y.to(device)  # move your data to device\n","\n","            pred = model(x)\n","            loss = criterion(pred, y)\n","            loss.backward()  # compute gradient (backpropagation)\n","            optimizer.step()  # update parameters\n","\n","            step += 1\n","            loss_record.append(loss.detach().item())\n","\n","            # display current epoch number and loss on tqdm progress bar\n","            train_pbar.set_description(f\"Epoch [{epoch+1}/{n_epochs}]\")\n","            train_pbar.set_postfix({\"loss\": loss.detach().item()})\n","\n","        mean_train_loss = sum(loss_record) / len(loss_record)\n","        writer.add_scalar(\"Loss/train\", mean_train_loss, step)\n","\n","        model.eval()  # set model to evaluation mode\n","        loss_record = []\n","        \n","        for x, y in valid_loader:\n","            x, y = x.to(device), y.to(device)\n","            with torch.no_grad():\n","                pred = model(x)\n","                loss = criterion(pred, y)\n","            \n","            loss_record.append(loss.item())\n","\n","        mean_valid_loss = sum(loss_record) / len(loss_record)\n","        print(f\"Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss}, Valid loss: {mean_valid_loss}\")\n","        writer.add_scalar(\"Loss/valid\", mean_valid_loss, step)\n","\n","        if mean_valid_loss < best_loss:\n","            best_loss = mean_valid_loss\n","            torch.save(model.state_dict(), config[\"save_path\"])\n","            print(\"Saving model with loss {:.3f}...\".format(best_loss))\n","            early_stop_count = 0\n","        else:\n","            early_stop_count += 1\n","\n","        if early_stop_count >= config[\"early_stop\"]:\n","            print(\"\\nModel is not improving, so we halt the training session.\")\n","            return"]},{"cell_type":"markdown","metadata":{},"source":["## Configurations"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","config = {\n","    \"seed\": 5201314,  # seed number\n","    \"select_all\": True, # whether to use all features\n","    \"valid_ratio\": 0.2,  # validation_size = train_size * valid_ratio\n","    \"n_epochs\": 10,  # number of epochs\n","    \"batch_size\": 256,\n","    \"learning_rate\": 1e-5,\n","    \"early_stop\": 600,  # if model has not imporved for this many consecutive epochs, stop training\n","    \"save_path\": \"./models/model.ckpt\"  # model will be saved here\n","}"]},{"cell_type":"markdown","metadata":{},"source":["## DataLoader"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","train_data size: (2408, 89),\n","valid_data size: (601, 89)\n","test_data size: (997, 88)\n","number of features: 88\n"]}],"source":["same_seed(config[\"seed\"])\n","\n","train_data, test_data = pd.read_csv(\"covid_train.csv\").values, pd.read_csv(\"covid_test.csv\").values\n","train_data, valid_data = train_valid_split(train_data, config[\"valid_ratio\"], config[\"seed\"])\n","\n","print(f\"\"\"\n","train_data size: {train_data.shape},\n","valid_data size: {valid_data.shape}\n","test_data size: {test_data.shape}\"\"\"\n",")\n","\n","x_train, x_valid, x_test, y_train, y_valid = select_feat(train_data, valid_data, test_data, config[\"select_all\"])\n","print(f\"number of features: {x_train.shape[1]}\")\n","\n","train_dataset, valid_dataset, test_dataset = COVID90Dataset(x_train, y_train), COVID90Dataset(x_valid, y_valid), COVID90Dataset(x_test)\n","\n","# pytorch dataloader loads pytorch dataset into batches\n","train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, pin_memory=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=config[\"batch_size\"], shuffle=True, pin_memory=True)\n","test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False, pin_memory=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Start Training"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/10 [00:00<?, ?it/s]"]},{"name":"stderr","output_type":"stream","text":["Epoch [1/10]: 100%|██████████| 10/10 [00:00<00:00, 81.20it/s, loss=99.6]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/10]: Train loss: 124.23699951171875, Valid loss: 110.10228474934895\n","Saving model with loss 110.102...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [2/10]: 100%|██████████| 10/10 [00:00<00:00, 151.56it/s, loss=95.4]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/10]: Train loss: 95.08738784790039, Valid loss: 78.36477406819661\n","Saving model with loss 78.365...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [3/10]: 100%|██████████| 10/10 [00:00<00:00, 180.97it/s, loss=66.5]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/10]: Train loss: 80.2079231262207, Valid loss: 71.30179341634114\n","Saving model with loss 71.302...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [4/10]: 100%|██████████| 10/10 [00:00<00:00, 150.05it/s, loss=74.7]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/10]: Train loss: 73.01406631469726, Valid loss: 67.63429005940755\n","Saving model with loss 67.634...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [5/10]: 100%|██████████| 10/10 [00:00<00:00, 147.89it/s, loss=82.8]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/10]: Train loss: 70.99601211547852, Valid loss: 62.68150329589844\n","Saving model with loss 62.682...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [6/10]: 100%|██████████| 10/10 [00:00<00:00, 150.43it/s, loss=67.3]"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/10]: Train loss: 70.48241119384765, Valid loss: 62.7203369140625"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [7/10]: 100%|██████████| 10/10 [00:00<00:00, 147.81it/s, loss=55.2]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/10]: Train loss: 58.941522216796876, Valid loss: 51.40812301635742\n","Saving model with loss 51.408...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [8/10]: 100%|██████████| 10/10 [00:00<00:00, 146.42it/s, loss=57.3]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/10]: Train loss: 51.26047554016113, Valid loss: 43.128859202067055\n","Saving model with loss 43.129...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [9/10]: 100%|██████████| 10/10 [00:00<00:00, 148.53it/s, loss=36]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [9/10]: Train loss: 45.366061782836915, Valid loss: 29.626510620117188\n","Saving model with loss 29.627...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch [10/10]: 100%|██████████| 10/10 [00:00<00:00, 150.02it/s, loss=106]"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/10]: Train loss: 136.80146179199218, Valid loss: 117.99960835774739\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["model = My_Model(input_dim=x_train.shape[1]).to(device)\n","trainer(train_loader, valid_loader, model, config, device)"]},{"cell_type":"markdown","metadata":{},"source":["## Plot learning curves with `tensorboard`"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["Reusing TensorBoard on port 6007 (pid 4072), started 0:01:02 ago. (Use '!kill 4072' to kill it.)"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-d061895d8a38d1c4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-d061895d8a38d1c4\");\n","          const url = new URL(\"http://localhost\");\n","          const port = 6007;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%reload_ext tensorboard\n","%tensorboard --logdir=./runs/"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMQB8BGlew21P7fl+jYSWjY","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
